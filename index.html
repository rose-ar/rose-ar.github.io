<!DOCTYPE HTML>

<html>

<head>
  <title>[Paper ID: 4704] ROSE</title>

  <link rel="stylesheet" href="template.css">
</head>

<body>
  <br>

  <center><span style="font-size: 44px; font-weight: bold;">A large-scale analysis on robustness in action recognition</span></center><br/>

  <table align=center width=600px style="padding-top: 0px; padding-bottom: 20px;">
    <tr>
      <td align=center width=600px>
        <center>
          <span style="font-size: 22px">Anonymous ECCV Submission</span>
        </center>
      </td>
    </tr>
  </table>

  <table align=center width=600px>
    <tr>
      <td align=center width=150px>
        <center>
          <span style="font-size: 22px">
            <a href="." target="_top">[Home]</a>
          </span>
        </center>
      </td>
      
      <td align=center width=150px>
        <center>
          <span style="font-size: 22px">
            <a href="." target="_top">[Paper]</a>
          </span>
        </center>
      </td>

      <td align=center width=150px>
        <center>
          <span style="font-size: 22px">
            <a href="./dataset.html" target="_top">[Dataset]</a>
          </span>
        </center>
      </td>
      
      <td align=center width=150px>
        <center>
          <span style="font-size: 22px">
            <a href="https://github.com/rose-ar/rose-ar.github.io" target="_top">[Code]</a>
          </span>
        </center>
      </td>

      <td align=center width=150px>
        <center>
          <span style="font-size: 22px">
            <a href="./examples.html" target="_top">[Examples]</a>
          </span>
        </center>
      </td>
      
    </tr>
  </table>

  <br>
  <br>


  <table align=center width=800px>
    <center><img src="./images/pie.png" width=600px /></center> <br>
    <center>Different real-world perturbations used in this study. </center>
  </table>

  <br>

  <br>

  <center>
    <h2>Abstract</h2>
  </center>
  <div style="width: 750px; margin: 0 auto; text-align=center; text-align: justify; text-justify: inter-ideograph;">
  We have seen a great progress in video action recognition
in recent years. There are several models based on convolutional neural
network (CNN) with some recent transformer based approaches which
provide state-of-the-art performance on existing benchmark datasets.
However, robustness has not been studied for these models which is
a critical aspect for real-world applications. In this work we perform
a large-scale robustness analysis of these existing models for video
action recognition. We mainly focus on robustness against distribution
shifts due to real-world perturbations instead of adversarial pertur-
bations. We propose four different benchmark datasets, HMDB-51P,
UCF-101P, Kinetics-400P, and SSv2P and study the robustness of
six different state-of-the-art action recognition models against 90 differ-
ent perturbations. The study reveals some interesting findings, 1) trans-
former based models are consistently more robust against most of the
perturbations when compared with CNN based models, 2) Pretraining
helps Transformer based models to be more robust to different pertur-
bations than CNN based models, and 3) All of the studied models are
robust to temporal perturbation on the Kinetics dataset, but not
on SSv2; this suggests temporal information is much more important for
action label prediction on SSv2 datasets than on the Kinetics dataset.
We hope that this study will serve as a benchmark for future research in
robust video action recognition.
  </div>
   <br>
  <br>
<hr> <br>
  <center>
    <h2>Sample perturbations</h2>
    <center>Severity increasing from left to right.</center>
  </center><br>
  <table align=center width=800px>
    <center>
      <img src="./images/hmdb-51p/Bill_Clinton_Statue_Unveiled_In_Kosovo_shake_hands_f_cm_np2_le_bad_0_box_jumbling_5.gif" width=150px />
      <img src="./images/hmdb-51p/Bill_Clinton_Statue_Unveiled_In_Kosovo_shake_hands_f_cm_np2_le_bad_0_box_jumbling_4.gif" width=150px />
      <img src="./images/hmdb-51p/Bill_Clinton_Statue_Unveiled_In_Kosovo_shake_hands_f_cm_np2_le_bad_0_box_jumbling_3.gif" width=150px />
      <img src="./images/hmdb-51p/Bill_Clinton_Statue_Unveiled_In_Kosovo_shake_hands_f_cm_np2_le_bad_0_box_jumbling_2.gif" width=150px />
      <img src="./images/hmdb-51p/Bill_Clinton_Statue_Unveiled_In_Kosovo_shake_hands_f_cm_np2_le_bad_0_box_jumbling_1.gif" width=150px />
    </center>
    <center>Box jumbling </center><br>
    <center>
      <img src="./images/kinetics-400p/--yCUKj4Oq4_000018_000028_random_rotate_1.gif" width=150px />
      <img src="./images/kinetics-400p/--yCUKj4Oq4_000018_000028_random_rotate_2.gif" width=150px />
      <img src="./images/kinetics-400p/--yCUKj4Oq4_000018_000028_random_rotate_3.gif" width=150px />
      <img src="./images/kinetics-400p/--yCUKj4Oq4_000018_000028_random_rotate_4.gif" width=150px />
      <img src="./images/kinetics-400p/--yCUKj4Oq4_000018_000028_random_rotate_5.gif" width=150px />      
    </center>
    <center>Random rotation</center><br>
    <center>
      <img src="./images/ucf-101p/v_ApplyEyeMakeup_g04_c03_motion_1.gif" width=150px />
      <img src="./images/ucf-101p/v_ApplyEyeMakeup_g04_c03_motion_2.gif" width=150px />
      <img src="./images/ucf-101p/v_ApplyEyeMakeup_g04_c03_motion_3.gif" width=150px />
      <img src="./images/ucf-101p/v_ApplyEyeMakeup_g04_c03_motion_4.gif" width=150px />
      <img src="./images/ucf-101p/v_ApplyEyeMakeup_g04_c03_motion_5.gif" width=150px />        
    </center>
    <center>Motion blur</center><br>
    
  </table>
  <br><br> <hr><br>
  <center>
    <h2>Robustness analysis</h2>
  </center>
  <table align=center width=800px>
    <center><img src="./images/teaser.png" width=600px /></center><br>
    <center>A performance and robustness visualization of action recognition models on UCF-101P. y-axis: relative robustness (lower is better), x-axis: accuracy on clean videos,  P indicates pre-training, and the size of circle indicates FLOPs. Transformer based models, such as MViT, not only performs better than CNN counterparts but are more robust against distribution shifts. However, without pre-training its robustness drops significantly.</center>
  </table>

 

  <br>

</body>

</html>
